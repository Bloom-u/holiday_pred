# 当前 GBDT（XGBoost）交通流量预测模型：理论基础说明

本文档从“为什么这样建模、每个模块对应的理论依据是什么”的角度，解释本仓库当前实现的 GBDT（XGBoost）日频交通流量预测系统（见 `src/gbdt/`）。

---

## 1. 建模视角：把时序预测转为监督学习

### 1.1 核心形式

当前系统本质是一个监督学习问题：对每一天 *t* 构造特征向量 **xₜ**，学习一个函数 **f(·)** 使得：

> ŷₜ = f(xₜ)

其中：
- 目标 **yₜ**：全国日流量（单变量）。
- 特征 **xₜ**：由“日历/节假日/春节窗口”特征 + “历史观测构成的动态特征”拼接得到。

这类方法在时间序列领域通常称为：
- **feature-based forecasting / regression-based forecasting**（基于特征工程的预测）
- 也可理解为 **autoregressive with exogenous features**（ARX 思路）：历史 y 的滞后项 + 外生（日历）特征。

### 1.2 为什么不直接用纯 ARIMA/ETS 或纯深度模型

对全国日流量这类序列，最强、最稳定的结构通常来自：
- 周期（周内、年内）
- 节假日与调休制度
- 春节窗口的非对称峰形

这些结构对树模型很“友好”，用显式特征表达后，GBDT 往往能在小数据量（仅 2~3 年）上得到比纯深度模型更稳的结果。

---

## 2. 模型选择：GBDT / XGBoost 的理论依据

### 2.1 GBDT 的基本原理（Boosting）

GBDT（Gradient Boosted Decision Trees）用**加性模型**逼近目标函数：

> f(x) = Σₘ η · hₘ(x)

其中：
- hₘ(x) 是第 m 棵回归树（弱学习器）
- η 是学习率（shrinkage，注意：这里是 boosting 的学习率概念，不是春节先验的 shrink）

每一步迭代拟合上一轮的残差/梯度方向，从而逐步降低损失函数。

### 2.2 为什么适合本问题

1) **非线性与交互**：节假日×周几×春节窗口位置×近期趋势之间的交互很强，树模型能自然学习。
2) **对特征尺度不敏感**：不需要复杂标准化。
3) **小样本更稳**：相比深度模型更不依赖海量数据。
4) **可解释性更强**：可通过特征重要性/分裂规则理解模型依赖哪些信号（尽管重要性不等同因果）。

---

## 3. 损失函数：MAE（绝对误差）的含义

当前默认使用 XGBoost 的：
- `objective="reg:absoluteerror"`（直接优化 L1）
- `eval_metric="mae"`

理论含义：
- L1 损失对应于**中位数回归**的性质：如果模型表达能力足够，最小化 MAE 会使预测倾向于条件分布的中位数。
- 相比 MSE，L1 对异常点更鲁棒（大误差不会被平方放大）。

适用性：
- 当“极端高峰/异常波动”存在时，MAE 往往比 MSE 更稳定。

---

## 4. 特征工程的理论基础

### 4.1 日历/节假日特征：把结构性外生因素显式化

实现：`src/holiday_feature.py` + `src/gbdt/features.py`

理论依据：
- 交通流量是“制度驱动”很强的序列：工作日/周末/法定节假日/调休工作日对人群出行行为造成系统性变化。
- 将这些制度因素编码为特征，相当于把“外生冲击/结构断点”从噪声中剥离出来，减少模型只能靠历史 y 盲猜的难度。

### 4.2 春节窗口特征：对局部非平稳的显式建模

实现：`src/gbdt/features.py:add_cny_features`

理论依据：
- 春节窗口是一个“局部强非平稳段”：均值、波动、趋势都显著不同于平时。
- 用 `days_to_cny` 等特征相当于建立“局部坐标系”，把“峰形”视为该坐标系下的可学习函数，而不是全年同一统计规律。

### 4.3 动态时序特征：有限记忆的自回归近似

实现：`src/gbdt/features.py:build_dynamic_features`（离线特征矩阵）与 `src/gbdt/forecasting.py:predict_tminus2_series`（t-2 场景滚动一步预测）。

典型特征：
- 滞后项（lags）：近似 AR(p) 的记忆
- 滚动均值/方差：近似局部平稳假设下的“近期水平/波动”
- `trend_7`、`slope_7/14`、`accel_7`：近似一阶/二阶趋势项（动量与加速度）

理论依据：
- 很多序列可被视为“缓慢变化的趋势 + 季节性 + 噪声”，用多尺度窗口统计量近似这一分解。
- 斜率/加速度属于通用的趋势信号，不依赖业务小技巧，能帮助模型对“持续增长/加速增长”更敏感。

### 4.4 Group Stats：目标编码（Target Encoding）式的类别先验

实现：`src/gbdt/features.py:compute_group_stats/apply_group_stats`，保存到 `models/gbdt/group_stats.json`

内容包括：
- `dow_mean/std`、`month_mean/std`、`holiday_type_mean/std`
- `cny_offset_mean`（春节窗口位置均值）

理论依据：
- 对类别特征做“训练集统计映射”，等价于把“该类别的历史平均水平/波动”作为一个弱先验输入。
- 这是一种典型的 target encoding 思路，能在样本不多时提升稳定性。

注意（与“信息泄露”的关系）：
- target encoding 的风险来自“统计时使用了未来/测试数据”。
- 本仓库通过年份掩码保证统计只用训练集（例如 2023 或 2023+2024），因此不会把 2025 信息泄露进特征。

---

## 5. t-2 信息约束下的一步滚动预测

实现：`src/gbdt/forecasting.py:predict_tminus2_series` + 动态特征 `delay=2`

定义：
- 对每个 t，动态特征严格只使用到 `t-2` 及以前的真实 y。

理论特点：
- 属于“direct one-step forecasting under delayed observations”（在观测延迟约束下的一步预测）。
- 相比递归，多步误差不累积，通常更稳。

为什么是 t-2：
- 这是业务系统假设（标签落地延迟）。如果实际可用到 t-1，则用 `delay=1` 可以进一步提升短期跟踪能力。

---

---

## 6. 分解式训练的理论基础：Baseline + Uplift 的加性分解

入口：`src/gbdt/train_decompose.py`

核心思想：
- 把 y 分解为“常规日基线”与“事件增量”：

> yₜ ≈ baseline(xₜ) + uplift(xₜ) · I(eventₜ)

其中 eventₜ 通常指节假日或春运窗口。

这与以下思想相近：
- “结构化残差建模”（先拟合大结构，再拟合剩余结构）
- “mixture-of-experts 的一种简化”（用显式 mask 决定在哪些样本上学习 uplift）
- “counterfactual baseline”（提供对照项 baseline_cf，用于分析假设下的基线水平）

适用场景：
- 你希望不仅预测，还希望解释“节假日/春运对流量的增量贡献”。

---

## 7. 无泄露（No Leakage）的理论与工程约束

无泄露不是“模型类型”决定的，而是“实验设计”决定的。当前分解建模系统的关键约束：
- 年份拆分：训练（2023+2024）不使用 2025 的真实值
- 动态特征使用 `shift(delay)`：避免把 yₜ 本身或未来信息用于 xₜ（见 `src/gbdt/features.py`）
- t-2 推理显式截断到 t-2：避免隐式使用 t-1 / t 的真实值（见 `src/gbdt/forecasting.py`）

---

## 8. 局限性与可扩展方向（理论层面）

局限性：
- 仍是单序列预测：无法做多变量系统级建模与根因定位（需要更多外部/多序列信号）。
- 春节先验（`cny_offset_mean`）可能在年份形态差异大时“压趋势”：它是稳定先验，优点是稳，缺点是对“异常高峰年”反应慢。

可扩展方向（按性价比排序）：
1) 引入外生变量（天气、迁徙指数、运力等）→ 从单变量升级到真正的 ARX/动态回归
2) 多步直接预测（multi-horizon）→ 减少递归漂移
3) 更细的场景校准（例如按 days_to_cny 分段的偏移/按周几分段）→ 但要严格防止过拟合
